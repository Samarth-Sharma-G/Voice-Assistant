# â˜ ï¸Â Oneâ€‘Piece Voice Assistant

> A Twilio **voice** bot that  
> â€“ streams raw audio to your server,  
> â€“ transcribes with Deepgram,  
> â€“ enriches every turn with RAG (Weaviateâ€¯+â€¯OpenAI),  
> â€“ speaks back with Deepgram TTS,  
> â€“ interrupts cleanly when the caller speaks, and  
> â€“ escalates to a human agent on request while logging the handâ€‘off in MySQL.

---

## âœ¨Â Features
|  |  |
|---|---|
| **Realâ€‘time media** | Twilio `<Connect><Stream>` â†’ WebSocket, no Functions. |
| **Retrievalâ€‘Augmented** | FastAPI microâ€‘service rewrites the query, runs a Weaviate `nearText`, and feeds chunks into GPT. |
| **Interruptâ€‘safe TTS** | `assistantTalking` flagÂ + `clear` event â‡’ never finishes the wrong answer. |
| **Escalation path** | GPT flag triggers `<Dial>` to `ESCALATION_NUMBER` and writes a row to RDS with the reason. |
| **Latency logs** | Perâ€‘turn RAG / GPT / TTS / total timing in the console. |

---

## ğŸ—‚ï¸Â Project layout

```
.
â”œâ”€ app.js                         # Node entry â€“ Twilio media, GPT, TTS, RAG
â”œâ”€ services/
â”‚  â”œâ”€ gpt-service.js
â”‚  â”œâ”€ rag-service.js              # thin HTTP client â†’ FastAPI
â”‚  â”œâ”€ stream-service.js
â”‚  â”œâ”€ transcription-service.js
â”‚  â””â”€ tts-service.js
â”œâ”€ services/RAG_service/          # Python FastAPI RAG microâ€‘service
â”‚  â”œâ”€ app.py
â”‚  â”œâ”€ __pycache__/
â”‚  â””â”€ requirements.txt
â”œâ”€ .env
â”œâ”€ package.json
â””â”€ README.md
```

---

## ğŸš€Â Quick start (local)

### 1Â CloneÂ & install

```bash
git clone https://github.com/yourâ€‘org/onepieceâ€‘voice.git
cd onepieceâ€‘voice

npm ci                           # Node deps
pip install -r services/RAG_service/requirements.txt
```

### 2Â CreateÂ `.env`

```env
# Twilio
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=xxxxxxxxxxxxxxxxxxxxxx
SERVER=xxxxxx.ngrok-free.app              # public HTTPS URL

# OpenAI / Deepgram
OPENAI_API_KEY=sk-...
DEEPGRAM_API_KEY=...

# Weaviate
WEAVIATE_URL=https://xxxxx.weaviate.cloud
WEAVIATE_API_KEY=xxxxxxxx
WEAVIATE_CLASS=onepiece
RAG_TOP_K=5

# MySQL (RDS)
DB_HOST=clearcall.c50y02uk0yr3.us-east-2.rds.amazonaws.com
DB_USER=admin
DB_PASSWORD=clear4Call
DB_NAME=clearcall
DB_PORT=3306

# Escalation
ESCALATION_NUMBER=+18005551234
```

> **MySQL table**  
> ```sql
> CREATE TABLE IF NOT EXISTS human_escalation (
>   id INT AUTO_INCREMENT PRIMARY KEY,
>   caller_number VARCHAR(32) NOT NULL,
>   escalated_to  VARCHAR(32) NOT NULL,
>   reason        VARCHAR(255) NOT NULL,
>   created_at    TIMESTAMP DEFAULT CURRENT_TIMESTAMP
> );
> ```

### 3Â Run both services

```bash
# terminalÂ 1 â€“ Node voice app
node app.js

# terminalÂ 2 â€“ FastAPI RAG
cd services/RAG_service
uvicorn app:app --host 0.0.0.0 --port 8001
```

### 4Â Expose to Twilio

```bash
ngrok http 6969
# set Twilio Voice webhook â†’ https://xxxx.ngrok-free.app/incoming
```

Call your Twilio number and try:  
*â€œHi, can you tell me about returns? â€¦ Actually, can I talk to a human?â€*

---

## ğŸ³Â Docker (optional)

```bash
docker compose up --build
```

`docker-compose.yml` (not included here) would spin up:

* `voice-app`Â (NodeÂ :6969)  
* `rag-service`Â (FastAPIÂ :8001)

---

## â˜ï¸Â Deploy

### Elastic Beanstalk (simple)

```bash
eb init --platform node.js
eb create onepieceâ€‘voiceâ€‘env
eb deploy
```
Do the same for `services/RAG_service` or combine with a multiâ€‘container Dockerrun.

### ECSÂ Fargate (scalable)

1. Build & push both images to **ECR**  
2. Create two **Task Definitions**  
3. Put them behind an **ALB** (`/` â†’ voiceâ€‘app, `/context` â†’ ragâ€‘service)  
4. Store secrets in **SSM Parameter Store** or **Secrets Manager**

---

## ğŸ“¡Â API reference

| Route | Service | Description |
|-------|---------|-------------|
| **POST /incoming** | Node | Twilio webhook â†’ returns TwiML `<Connect><Stream>` |
| **WS /connection** | Node | Bidirectional media WebSocket |
| **POST /context**  | FastAPI | `{question,history,caller_number,escalated_to}` â‡’ `{context,is_escalation}` |

---

## ğŸ“Â License
MIT Â©Â 2025Â Samarth Sharma
